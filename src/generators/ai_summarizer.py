import google.generativeai as genai
from datetime import datetime
from typing import List
import random
import sys
import os

# ãƒ‘ã‚¹ã®è¨­å®š
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from collectors.base_collector import Article
from utils.rate_limiter import rate_limited, retry_with_backoff
from utils.constants import TARGET_ARTICLE_LENGTH, MAX_ARTICLES_PER_POST, DATE_FORMAT
from utils.logger import get_logger

class AISummarizer:
    def __init__(self, config):
        self.config = config
        self.logger = get_logger("ai_summarizer")
        self.templates = config.templates
        
        # Gemini APIè¨­å®š
        api_key = config.gemini_api_key
        if not api_key:
            raise ValueError("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
    
    def generate_article(self, articles: List[Article]) -> str:
        """è¨˜äº‹ä¸€è¦§ã‹ã‚‰ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆ"""
        if not articles:
            raise ValueError("è¨˜äº‹ãŒç©ºã§ã™")
        
        try:
            # ãƒ¡ã‚¤ãƒ³: Gemini APIã§ç”Ÿæˆ
            content = self._generate_with_gemini(articles)
            print("âœ… Gemini APIã§è¨˜äº‹ç”Ÿæˆå®Œäº†")
            return content
        
        except Exception as e:
            print(f"âš ï¸  Gemini APIå¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ollama
            try:
                content = self._generate_with_ollama(articles)
                print("âœ… ollamaã§è¨˜äº‹ç”Ÿæˆå®Œäº†")
                return content
            except Exception as e2:
                print(f"âŒ ollamaç”Ÿæˆã‚‚å¤±æ•—: {e2}")
                raise Exception(f"è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚Gemini: {e}, Ollama: {e2}")
    
    @rate_limited('gemini_api', max_calls_per_minute=15)
    @retry_with_backoff(max_retries=2, base_delay=2.0)
    def _generate_with_gemini(self, articles: List[Article]) -> str:
        """Gemini APIã§è¨˜äº‹ç”Ÿæˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ»ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
        today = datetime.now().strftime(DATE_FORMAT)
        article_count = len(articles)
        
        # è¨˜äº‹æƒ…å ±ã‚’æ•´ç†
        article_info = []
        for i, article in enumerate(articles[:MAX_ARTICLES_PER_POST]):
            article_info.append(f"""
è¨˜äº‹{i+1}:
- ã‚¿ã‚¤ãƒˆãƒ«: {article.title}
- è¦ç´„: {article.summary}
- URL: {article.url}
- ã‚½ãƒ¼ã‚¹: {article.source}
- ã‚¹ã‚³ã‚¢: {article.score}
""")
        
        prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒƒã‚¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’å…ƒã«ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

æ¡ä»¶:
- æ–‡å­—æ•°: ç´„{TARGET_ARTICLE_LENGTH}æ–‡å­—
- èª­äº†æ™‚é–“: 3-4åˆ†
- è‡ªç„¶ã§äººé–“ã‚‰ã—ã„æ–‡ç« ï¼ˆè¨˜è€…ãŒæ›¸ã„ãŸã‚ˆã†ãªæ–‡ä½“ï¼‰
- çµµæ–‡å­—ã¯æœ€å°é™ã«æŠ‘åˆ¶ï¼ˆ1-2å€‹ç¨‹åº¦ã¾ã§ï¼‰
- å°‚é–€ç”¨èªã¯åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜

è¨˜äº‹æ§‹æˆ:
# ä»Šæ—¥ã®ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆ{today}ï¼‰

æœ¬æ—¥æ³¨ç›®ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’{article_count}è¨˜äº‹ã”ç´¹ä»‹ã—ã¾ã™ã€‚

## [è¨˜äº‹1ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’åˆ†ã‹ã‚Šã‚„ã™ã]
**æ¦‚è¦**: [è¦ç‚¹ã‚’ç°¡æ½”ã« 50æ–‡å­—ç¨‹åº¦]
**è©³ç´°**: [èƒŒæ™¯ã‚„å½±éŸ¿ã«ã¤ã„ã¦è©³ã—ã 100-150æ–‡å­—]
[â†’ å…ƒè¨˜äº‹ã‚’èª­ã‚€]({article.url})

[ä»–ã®è¨˜äº‹ã‚‚åŒæ§˜ã®æ§‹æˆã§...]

## ä»Šæ—¥ã®ãƒã‚¤ãƒ³ãƒˆ
- [é‡è¦ãªãƒˆãƒ¬ãƒ³ãƒ‰1]
- [æ³¨ç›®ã™ã¹ãå‹•å‘2] 
- [ä»Šå¾Œã®å±•æœ›3]

å…¥åŠ›è¨˜äº‹ãƒ‡ãƒ¼ã‚¿:
{"".join(article_info)}

â€»è‡ªç„¶ãªãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æ–‡ä½“ã§æ›¸ã„ã¦ãã ã•ã„
â€»æŠ€è¡“çš„ãªå†…å®¹ã‚‚ä¸€èˆ¬èª­è€…ã«åˆ†ã‹ã‚Šã‚„ã™ã
â€»ã€Œã§ã™ãƒ»ã¾ã™èª¿ã€ã§ä¸å¯§ã«
"""

        response = self.model.generate_content(prompt)
        return response.text
    
    def _generate_with_ollama(self, articles: List[Article]) -> str:
        """ollamaã§è¨˜äº‹ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            import ollama
        except ImportError:
            raise ImportError("ollamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        today = datetime.now().strftime(DATE_FORMAT)
        article_count = len(articles)
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        article_summaries = []
        for article in articles[:MAX_ARTICLES_PER_POST]:
            article_summaries.append(f"- {article.title}: {article.summary[:100]}")
        
        prompt = f"""
ä»¥ä¸‹ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å…ƒã«ã€{TARGET_ARTICLE_LENGTH}æ–‡å­—ç¨‹åº¦ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: ä»Šæ—¥ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚ï¼ˆ{today}ï¼‰

è¨˜äº‹æ•°: {article_count}è¨˜äº‹

è¨˜äº‹å†…å®¹:
{chr(10).join(article_summaries)}

æ§‹æˆ:
1. å°å…¥æ–‡
2. å„è¨˜äº‹ã®è¦ç´„ã¨è©³ç´°
3. ã¾ã¨ã‚

è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""

        response = ollama.generate(
            model='llama3.1',
            prompt=prompt
        )
        
        return response['response']
    
    def _select_emoji(self) -> str:
        """ãƒ©ãƒ³ãƒ€ãƒ ã«çµµæ–‡å­—ã‚’é¸æŠ"""
        emojis = self.templates.get('emojis', ['ğŸš€', 'ğŸ¤–', 'ğŸ’¡', 'ğŸ”¬', 'âš¡'])
        return random.choice(emojis)