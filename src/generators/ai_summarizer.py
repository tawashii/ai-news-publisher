import google.generativeai as genai
from datetime import datetime
from typing import List
import random
import sys
import os

# ãƒ‘ã‚¹ã®è¨­å®š
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from collectors.base_collector import Article
from utils.rate_limiter import rate_limited, retry_with_backoff
from utils.constants import TARGET_ARTICLE_LENGTH, MAX_ARTICLES_PER_POST, DATE_FORMAT
from utils.logger import get_logger

class AISummarizer:
    def __init__(self, config):
        self.config = config
        self.logger = get_logger("ai_summarizer")
        self.templates = config.templates
        
        # Gemini APIè¨­å®š
        api_key = config.gemini_api_key
        if not api_key:
            raise ValueError("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
    
    def generate_article(self, articles: List[Article]) -> str:
        """è¨˜äº‹ä¸€è¦§ã‹ã‚‰ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆ"""
        if not articles:
            raise ValueError("è¨˜äº‹ãŒç©ºã§ã™")
        
        try:
            # ãƒ¡ã‚¤ãƒ³: Gemini APIã§ç”Ÿæˆ
            content = self._generate_with_gemini(articles)
            print("âœ… Gemini APIã§è¨˜äº‹ç”Ÿæˆå®Œäº†")
            return content
        
        except Exception as e:
            print(f"âš ï¸  Gemini APIå¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ollama
            try:
                content = self._generate_with_ollama(articles)
                print("âœ… ollamaã§è¨˜äº‹ç”Ÿæˆå®Œäº†")
                return content
            except Exception as e2:
                print(f"âŒ ollamaç”Ÿæˆã‚‚å¤±æ•—: {e2}")
                raise Exception(f"è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚Gemini: {e}, Ollama: {e2}")
    
    @rate_limited('gemini_api', max_calls_per_minute=15)
    @retry_with_backoff(max_retries=2, base_delay=2.0)
    def _generate_with_gemini(self, articles: List[Article]) -> str:
        """Gemini APIã§è¨˜äº‹ç”Ÿæˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ»ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
        today = datetime.now().strftime(DATE_FORMAT)
        article_count = len(articles)
        
        # è¨˜äº‹æƒ…å ±ã‚’æ•´ç†
        article_info = []
        for i, article in enumerate(articles[:MAX_ARTICLES_PER_POST]):
            article_info.append(f"""
è¨˜äº‹{i+1}:
- ã‚¿ã‚¤ãƒˆãƒ«: {article.title}
- è¦ç´„: {article.summary}
- URL: {article.url}
- ã‚½ãƒ¼ã‚¹: {article.source}
- ã‚¹ã‚³ã‚¢: {article.score}
""")
        
        prompt = f"""
ä»¥ä¸‹ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å‚è€ƒã«ã€æ™®é€šã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã¨ã—ã¦è‡ªç„¶ã«æ›¸ã„ã¦ãã ã•ã„ã€‚

é‡è¦ãªæ¡ä»¶:
- æ–‡å­—æ•°: ç´„{TARGET_ARTICLE_LENGTH}æ–‡å­—
- æ™®é€šã®äººãŒæ›¸ã„ãŸã‚ˆã†ãªè‡ªç„¶ãªæ–‡ç« 
- ã€Œã”ç´¹ä»‹ã—ã¾ã™ã€ã€Œè©³ã—ãè§£èª¬ã€ãªã©ã®AIçš„è¡¨ç¾ã¯ä½¿ã‚ãªã„
- çµµæ–‡å­—ã¯æ§ãˆã‚ã«ï¼ˆå¤šãã¦ã‚‚1-2å€‹ï¼‰
- å …ã™ããšã€è¦ªã—ã¿ã‚„ã™ã„æ–‡ä½“

æ›¸ãæ–¹ã®ã‚¤ãƒ¡ãƒ¼ã‚¸:
# ä»Šæ—¥ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆ{today}ï¼‰

æ°—ã«ãªã‚‹AIé–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã„ãã¤ã‹ã‚ã£ãŸã®ã§ã€ã¾ã¨ã‚ã¦ã¿ã¾ã—ãŸã€‚

## [è‡ªç„¶ãªã‚¿ã‚¤ãƒˆãƒ«]
[æ™®é€šã«èª¬æ˜ã™ã‚‹æ–‡ç« ã€‚ã€Œã€œãŒç™ºè¡¨ã•ã‚Œã¾ã—ãŸã€ã€Œã€œãŒè©±é¡Œã«ãªã£ã¦ã„ã¾ã™ã€ãªã©ã€è‡ªç„¶ãªè¡¨ç¾ã§]

[è©³ã—ã„å†…å®¹ã‚’2-3æ–‡ã§ã€‚å°‚é–€ç”¨èªãŒã‚ã‚Œã°ç°¡å˜ã«èª¬æ˜]

[â†’ è©³ç´°ã¯ã“ã¡ã‚‰]({article.url})

## æœ€è¿‘ã®å‹•å‘
- [è‡ªç„¶ãªæ–‡ã§æ°—ã«ãªã‚‹ç‚¹]
- [ç‡ç›´ãªæ„Ÿæƒ³ã‚„æ„è¦‹]
- [ä»Šå¾Œã©ã†ãªã‚‹ã‹ã®äºˆæƒ³]

å‚è€ƒãƒ‡ãƒ¼ã‚¿:
{"".join(article_info)}

â€»çµ¶å¯¾ã«AIçš„ãªå®šå‹è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„
â€»æ™®é€šã®ãƒ–ãƒ­ã‚¬ãƒ¼ãŒæ›¸ã„ãŸã‚ˆã†ãªè‡ªç„¶ã•ã‚’é‡è¦–
â€»é›£ã—ã„è©±ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãã€ã§ã‚‚ä¸Šã‹ã‚‰ç›®ç·šã«ãªã‚‰ãªã„
"""

        response = self.model.generate_content(prompt)
        return response.text
    
    def _generate_with_ollama(self, articles: List[Article]) -> str:
        """ollamaã§è¨˜äº‹ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            import ollama
        except ImportError:
            raise ImportError("ollamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        today = datetime.now().strftime(DATE_FORMAT)
        article_count = len(articles)
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        article_summaries = []
        for article in articles[:MAX_ARTICLES_PER_POST]:
            article_summaries.append(f"- {article.title}: {article.summary[:100]}")
        
        prompt = f"""
ä»¥ä¸‹ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å…ƒã«ã€{TARGET_ARTICLE_LENGTH}æ–‡å­—ç¨‹åº¦ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: ä»Šæ—¥ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚ï¼ˆ{today}ï¼‰

è¨˜äº‹æ•°: {article_count}è¨˜äº‹

è¨˜äº‹å†…å®¹:
{chr(10).join(article_summaries)}

æ§‹æˆ:
1. å°å…¥æ–‡
2. å„è¨˜äº‹ã®è¦ç´„ã¨è©³ç´°
3. ã¾ã¨ã‚

è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""

        response = ollama.generate(
            model='llama3.1',
            prompt=prompt
        )
        
        return response['response']
    
    def _select_emoji(self) -> str:
        """ãƒ©ãƒ³ãƒ€ãƒ ã«çµµæ–‡å­—ã‚’é¸æŠ"""
        emojis = self.templates.get('emojis', ['ğŸš€', 'ğŸ¤–', 'ğŸ’¡', 'ğŸ”¬', 'âš¡'])
        return random.choice(emojis)