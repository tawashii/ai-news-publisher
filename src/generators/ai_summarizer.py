import google.generativeai as genai
from datetime import datetime
from typing import List
import random
from ..collectors.base_collector import Article
from ..utils.rate_limiter import rate_limited, retry_with_backoff
from ..utils.constants import TARGET_ARTICLE_LENGTH, MAX_ARTICLES_PER_POST, DATE_FORMAT
from ..utils.logger import get_logger

class AISummarizer:
    def __init__(self, config):
        self.config = config
        self.logger = get_logger("ai_summarizer")
        self.templates = config.templates
        
        # Gemini APIè¨­å®š
        api_key = config.gemini_api_key
        if not api_key:
            raise ValueError("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
    
    def generate_article(self, articles: List[Article]) -> str:
        """è¨˜äº‹ä¸€è¦§ã‹ã‚‰ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆ"""
        if not articles:
            raise ValueError("è¨˜äº‹ãŒç©ºã§ã™")
        
        try:
            # ãƒ¡ã‚¤ãƒ³: Gemini APIã§ç”Ÿæˆ
            content = self._generate_with_gemini(articles)
            print("âœ… Gemini APIã§è¨˜äº‹ç”Ÿæˆå®Œäº†")
            return content
        
        except Exception as e:
            print(f"âš ï¸  Gemini APIå¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ollama
            try:
                content = self._generate_with_ollama(articles)
                print("âœ… ollamaã§è¨˜äº‹ç”Ÿæˆå®Œäº†")
                return content
            except Exception as e2:
                print(f"âŒ ollamaç”Ÿæˆã‚‚å¤±æ•—: {e2}")
                raise Exception(f"è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚Gemini: {e}, Ollama: {e2}")
    
    @rate_limited('gemini_api', max_calls_per_minute=15)
    @retry_with_backoff(max_retries=2, base_delay=2.0)
    def _generate_with_gemini(self, articles: List[Article]) -> str:
        """Gemini APIã§è¨˜äº‹ç”Ÿæˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ»ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
        today = datetime.now().strftime(DATE_FORMAT)
        article_count = len(articles)
        
        # è¨˜äº‹æƒ…å ±ã‚’æ•´ç†
        article_info = []
        for i, article in enumerate(articles[:MAX_ARTICLES_PER_POST]):
            article_info.append(f"""
è¨˜äº‹{i+1}:
- ã‚¿ã‚¤ãƒˆãƒ«: {article.title}
- è¦ç´„: {article.summary}
- URL: {article.url}
- ã‚½ãƒ¼ã‚¹: {article.source}
- ã‚¹ã‚³ã‚¢: {article.score}
""")
        
        prompt = f"""
ä»¥ä¸‹ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’å…ƒã«ã€èª­ã¿ã‚„ã™ã„ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

æ¡ä»¶:
- æ–‡å­—æ•°: ç´„{TARGET_ARTICLE_LENGTH}æ–‡å­—
- èª­äº†æ™‚é–“: 3-4åˆ†
- è‡ªç„¶ã§äººé–“ã‚‰ã—ã„æ–‡ç« 
- AIãŒæ›¸ã„ãŸã¨åˆ†ã‹ã‚‰ãªã„ã‚ˆã†ãªæ–‡ä½“
- çµµæ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨ã—ã¦è¦ªã—ã¿ã‚„ã™ã

è¨˜äº‹æ§‹æˆ:
# ä»Šæ—¥ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚ï¼ˆ{today}ï¼‰

ä»Šæ—¥æ³¨ç›®ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’{article_count}è¨˜äº‹ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦ãŠå±Šã‘ã—ã¾ã™ã€‚

## ğŸš€ [è¨˜äº‹1ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’é­…åŠ›çš„ã«]
**è¦ç´„**: [ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¦ç´„ 50æ–‡å­—ç¨‹åº¦]
**è©³ç´°**: [è©³ã—ã„è§£èª¬ã‚„æ„ç¾©ã«ã¤ã„ã¦ 100-150æ–‡å­—]
[å…ƒè¨˜äº‹ã‚’èª­ã‚€]({article.url})

[ä»–ã®è¨˜äº‹ã‚‚åŒæ§˜ã®æ§‹æˆã§...]

## ğŸ’¡ ä»Šæ—¥ã®ã¾ã¨ã‚
- [ä»Šæ—¥ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ1]
- [ä»Šæ—¥ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ2] 
- [ä»Šæ—¥ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ3]

å…¥åŠ›è¨˜äº‹ãƒ‡ãƒ¼ã‚¿:
{"".join(article_info)}

â€»çµµæ–‡å­—ã¯ä»¥ä¸‹ã‹ã‚‰é¸æŠ: ğŸš€ ğŸ¤– ğŸ’¡ ğŸ”¬ âš¡ ğŸ¯ ğŸŒŸ ğŸ“Š
â€»è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã¯å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚ˆã‚Šé­…åŠ›çš„ã«æ”¹å¤‰ã—ã¦ãã ã•ã„
â€»ã€Œã§ã™ãƒ»ã¾ã™èª¿ã€ã§è¦ªã—ã¿ã‚„ã™ãæ›¸ã„ã¦ãã ã•ã„
"""

        response = self.model.generate_content(prompt)
        return response.text
    
    def _generate_with_ollama(self, articles: List[Article]) -> str:
        """ollamaã§è¨˜äº‹ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            import ollama
        except ImportError:
            raise ImportError("ollamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        today = datetime.now().strftime(DATE_FORMAT)
        article_count = len(articles)
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        article_summaries = []
        for article in articles[:MAX_ARTICLES_PER_POST]:
            article_summaries.append(f"- {article.title}: {article.summary[:100]}")
        
        prompt = f"""
ä»¥ä¸‹ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å…ƒã«ã€{TARGET_ARTICLE_LENGTH}æ–‡å­—ç¨‹åº¦ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: ä»Šæ—¥ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚ï¼ˆ{today}ï¼‰

è¨˜äº‹æ•°: {article_count}è¨˜äº‹

è¨˜äº‹å†…å®¹:
{chr(10).join(article_summaries)}

æ§‹æˆ:
1. å°å…¥æ–‡
2. å„è¨˜äº‹ã®è¦ç´„ã¨è©³ç´°
3. ã¾ã¨ã‚

è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""

        response = ollama.generate(
            model='llama3.1',
            prompt=prompt
        )
        
        return response['response']
    
    def _select_emoji(self) -> str:
        """ãƒ©ãƒ³ãƒ€ãƒ ã«çµµæ–‡å­—ã‚’é¸æŠ"""
        emojis = self.templates.get('emojis', ['ğŸš€', 'ğŸ¤–', 'ğŸ’¡', 'ğŸ”¬', 'âš¡'])
        return random.choice(emojis)